# 阿里云语音服务 Java SDK 完整使用文档

一个用于调用阿里云智能语音交互（NLS）提供的 ASR（语音转写）和 TTS（文本转语音）的 Java 项目。项目基于 Maven 构建，提供获取临时 Token、调用 ASR 与 TTS 接口的轻量封装以及示例命令行入口。

## 目录

1. [快速开始](#快速开始)
2. [构建JAR包](#构建jar包)
3. [Java应用中使用](#java应用中使用)
4. [Android服务调用](#android服务调用)
5. [ASR功能详解](#asr功能详解)
6. [配置说明](#配置说明)
7. [常见问题](#常见问题)

---

## 快速开始

### 前置要求

- JDK 17 或更高版本
- Maven 3.6+
- 阿里云账号和相应的API密钥

### 环境变量配置

**ASR功能需要：**
```bash
export DASHSCOPE_API_KEY="your-api-key"
# 可选配置
export DASHSCOPE_BASE_URL="wss://dashscope.aliyuncs.com/api-ws/v1/inference"
export DASHSCOPE_ASR_MODEL="fun-asr-realtime"
export DASHSCOPE_ASR_LANGUAGE_HINTS="zh,en"
```

**TTS功能需要：**
```bash
export ALIBABA_CLOUD_ACCESS_KEY_ID="your-access-key-id"
export ALIBABA_CLOUD_ACCESS_KEY_SECRET="your-access-key-secret"
export ALIBABA_CLOUD_APP_KEY="your-app-key"
```

---

## 构建JAR包

### 构建所有JAR包

```bash
mvn clean package
```

构建完成后，在 `target/` 目录下会生成：

- **`tangyu-aliyun-speech-0.1.0.jar`** - 普通jar包（不含依赖，供其他项目使用）
- **`tangyu-aliyun-speech-0.1.0-executable.jar`** - 可执行fat jar（包含所有依赖，可直接运行）

### 作为可执行JAR使用

直接运行，无需额外配置依赖：

```bash
# 同步识别音频文件
java -jar target/tangyu-aliyun-speech-0.1.0-executable.jar asr sample.pcm pcm 16000

# 流式识别（从麦克风）
java -jar target/tangyu-aliyun-speech-0.1.0-executable.jar asr-stream pcm 16000

# 文本转语音
java -jar target/tangyu-aliyun-speech-0.1.0-executable.jar tts "你好" xiaoyun wav 16000 output.wav
```

---

## Java应用中使用

### 方式1：Maven项目

#### 安装到本地Maven仓库

```bash
mvn install
```

#### 在pom.xml中添加依赖

```xml
<dependency>
    <groupId>com.example</groupId>
    <artifactId>tangyu-aliyun-speech</artifactId>
    <version>0.1.0</version>
</dependency>
```

**注意：** 使用普通jar时，需要同时添加所有依赖：

```xml
<dependencies>
    <dependency>
        <groupId>com.example</groupId>
        <artifactId>tangyu-aliyun-speech</artifactId>
        <version>0.1.0</version>
    </dependency>
    
    <!-- 需要添加的依赖 -->
    <dependency>
        <groupId>com.alibaba</groupId>
        <artifactId>dashscope-sdk-java</artifactId>
        <version>2.22.3</version>
    </dependency>
    <dependency>
        <groupId>com.aliyun</groupId>
        <artifactId>aliyun-java-sdk-core</artifactId>
        <version>4.6.4</version>
    </dependency>
    <dependency>
        <groupId>com.squareup.okhttp3</groupId>
        <artifactId>okhttp</artifactId>
        <version>4.12.0</version>
    </dependency>
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
        <version>2.17.1</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-api</artifactId>
        <version>2.0.13</version>
    </dependency>
</dependencies>
```

### 方式2：Gradle项目

```gradle
dependencies {
    implementation 'com.example:tangyu-aliyun-speech:0.1.0'
    
    // 需要添加的依赖
    implementation 'com.alibaba:dashscope-sdk-java:2.22.3'
    implementation 'com.aliyun:aliyun-java-sdk-core:4.6.4'
    implementation 'com.squareup.okhttp3:okhttp:4.12.0'
    implementation 'com.fasterxml.jackson.core:jackson-databind:2.17.1'
    implementation 'org.slf4j:slf4j-api:2.0.13'
}
```

### 方式3：直接使用JAR文件

将 `tangyu-aliyun-speech-0.1.0.jar` 复制到项目的 `libs/` 目录，编译时添加到 classpath。

### 代码示例

#### ASR同步识别

```java
import com.example.tangyu.config.DashScopeConfig;
import com.example.tangyu.speech.AsrClient;
import java.nio.file.Paths;

DashScopeConfig config = DashScopeConfig.fromEnvironment();
AsrClient client = new AsrClient(config);
String result = client.transcribe(Paths.get("audio.pcm"), "pcm", 16000);
System.out.println(result);
```

#### ASR流式识别

```java
import com.alibaba.dashscope.audio.asr.recognition.Recognition;
import com.example.tangyu.config.DashScopeConfig;
import com.example.tangyu.speech.AsrClient;
import com.example.tangyu.speech.AsrResultHandler;

DashScopeConfig config = DashScopeConfig.fromEnvironment();
AsrClient client = new AsrClient(config);
AsrResultHandler handler = new AsrResultHandler();

Recognition recognition = client.startStreaming("pcm", 16000, handler);

// 发送音频数据
byte[] audioData = getAudioData();
client.sendAudioFrame(recognition, audioData, 0, audioData.length);

// 停止
client.stopStreaming(recognition);
System.out.println(handler.getFullText());
```

#### TTS

```java
import com.example.tangyu.config.CredentialConfig;
import com.example.tangyu.speech.TokenClient;
import com.example.tangyu.speech.TtsClient;
import java.nio.file.Paths;

CredentialConfig config = CredentialConfig.fromEnvironment();
TokenClient tokenClient = new TokenClient(config);
TtsClient client = new TtsClient(config, tokenClient);

client.synthesizeToFile("你好", "xiaoyun", "wav", 16000, Paths.get("output.wav"));
```

### Spring Boot项目中使用

#### 1. 添加依赖

```xml
<dependency>
    <groupId>com.example</groupId>
    <artifactId>tangyu-aliyun-speech</artifactId>
    <version>0.1.0</version>
</dependency>
```

#### 2. 配置Bean

```java
@Configuration
public class SpeechConfig {
    
    @Bean
    @ConditionalOnProperty(name = "speech.asr.enabled", havingValue = "true")
    public AsrClient asrClient() {
        DashScopeConfig config = DashScopeConfig.fromEnvironment();
        return new AsrClient(config);
    }
    
    @Bean
    @ConditionalOnProperty(name = "speech.tts.enabled", havingValue = "true")
    public TtsClient ttsClient() {
        CredentialConfig config = CredentialConfig.fromEnvironment();
        TokenClient tokenClient = new TokenClient(config);
        return new TtsClient(config, tokenClient);
    }
}
```

#### 3. 在Service中使用

```java
@Service
public class SpeechService {
    
    @Autowired
    private AsrClient asrClient;
    
    @Autowired
    private TtsClient ttsClient;
    
    public String transcribe(Path audioFile) {
        return asrClient.transcribe(audioFile, "pcm", 16000);
    }
    
    public Path synthesize(String text) {
        Path output = Paths.get("output.wav");
        ttsClient.synthesizeToFile(text, "xiaoyun", "wav", 16000, output);
        return output;
    }
}
```

---

## Android服务调用

### 前置要求

- Android Studio
- Android SDK API Level 21+ (Android 5.0+)
- 网络权限

**注意**：支持 Java 和 Kotlin，Kotlin 可以直接调用 Java 库，无需任何转换。Kotlin 示例请查看 [Android-Kotlin示例.md](./Android-Kotlin示例.md)

### 1. 添加依赖

#### 方式一：使用本地Maven仓库

**步骤1：** 将jar包安装到本地Maven仓库
```bash
mvn install
```

**步骤2：** 在项目的 `build.gradle` 中添加：

```gradle
repositories {
    mavenLocal()  // 添加本地Maven仓库
    google()
    mavenCentral()
}

dependencies {
    implementation 'com.example:tangyu-aliyun-speech:0.1.0'
    
    // 需要添加的依赖
    implementation 'com.alibaba:dashscope-sdk-java:2.22.3'
    implementation 'com.aliyun:aliyun-java-sdk-core:4.6.4'
    implementation 'com.squareup.okhttp3:okhttp:4.12.0'
    implementation 'com.fasterxml.jackson.core:jackson-databind:2.17.1'
    implementation 'org.slf4j:slf4j-api:2.0.13'
    
    // Android日志实现
    implementation 'org.slf4j:slf4j-android:1.7.36'
}
```

#### 方式二：直接使用AAR/JAR文件

**步骤1：** 将jar文件复制到 `app/libs/` 目录

**步骤2：** 在 `app/build.gradle` 中添加：

```gradle
dependencies {
    implementation fileTree(dir: 'libs', include: ['*.jar'])
    
    // 需要添加的依赖（同上）
}
```

### 2. 添加权限

在 `AndroidManifest.xml` 中添加：

```xml
<uses-permission android:name="android.permission.INTERNET" />
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
```

### 3. 配置API密钥

**重要：** Android中不能使用环境变量，必须通过代码直接创建配置对象。

#### 方式一：直接创建配置对象（推荐）

```java
import com.example.tangyu.config.DashScopeConfig;
import com.example.tangyu.config.CredentialConfig;
import com.example.tangyu.speech.AsrClient;
import com.example.tangyu.speech.TtsClient;
import com.example.tangyu.speech.TokenClient;

// ASR配置（直接使用API Key）
DashScopeConfig dashScopeConfig = new DashScopeConfig(
    "sk-dcc82f29f97348deacf9969d27d209bf",  // API Key
    "wss://dashscope.aliyuncs.com/api-ws/v1/inference",  // WebSocket地址（可选，有默认值）
    "fun-asr-realtime",  // 模型名称（可选，有默认值）
    new String[]{"zh", "en"}  // 语言提示（可选，有默认值）
);

// 创建ASR客户端
AsrClient asrClient = new AsrClient(dashScopeConfig);

// TTS配置（如果需要TTS功能）
CredentialConfig credentialConfig = new CredentialConfig(
    "your-access-key-id",      // AccessKey ID
    "your-access-key-secret",  // AccessKey Secret
    "your-app-key"             // AppKey
);

TokenClient tokenClient = new TokenClient(credentialConfig);
TtsClient ttsClient = new TtsClient(credentialConfig, tokenClient);
```

#### 方式二：创建配置工具类（便于管理）

```java
public class SpeechConfigHelper {
    // 你的API密钥（建议放在安全的地方，不要硬编码）
    private static final String DASHSCOPE_API_KEY = "sk-dcc82f29f97348deacf9969d27d209bf";
    private static final String ACCESS_KEY_ID = "your-access-key-id";
    private static final String ACCESS_KEY_SECRET = "your-access-key-secret";
    private static final String APP_KEY = "your-app-key";
    
    /**
     * 创建ASR配置
     */
    public static DashScopeConfig createDashScopeConfig() {
        return new DashScopeConfig(
            DASHSCOPE_API_KEY,
            null,  // 使用默认值
            null,  // 使用默认值
            null   // 使用默认值
        );
    }
    
    /**
     * 创建TTS配置
     */
    public static CredentialConfig createCredentialConfig() {
        return new CredentialConfig(
            ACCESS_KEY_ID,
            ACCESS_KEY_SECRET,
            APP_KEY
        );
    }
    
    /**
     * 创建ASR客户端
     */
    public static AsrClient createAsrClient() {
        return new AsrClient(createDashScopeConfig());
    }
    
    /**
     * 创建TTS客户端
     */
    public static TtsClient createTtsClient() {
        CredentialConfig config = createCredentialConfig();
        TokenClient tokenClient = new TokenClient(config);
        return new TtsClient(config, tokenClient);
    }
}
```

#### 方式三：从SharedPreferences读取（适合动态配置）

```java
public class ConfigManager {
    private SharedPreferences prefs;
    
    public ConfigManager(Context context) {
        prefs = context.getSharedPreferences("speech_config", Context.MODE_PRIVATE);
    }
    
    public DashScopeConfig getDashScopeConfig() {
        String apiKey = prefs.getString("DASHSCOPE_API_KEY", "");
        if (apiKey.isEmpty()) {
            throw new IllegalStateException("DASHSCOPE_API_KEY not configured");
        }
        return new DashScopeConfig(apiKey, null, null, null);
    }
    
    public CredentialConfig getCredentialConfig() {
        String keyId = prefs.getString("ACCESS_KEY_ID", "");
        String keySecret = prefs.getString("ACCESS_KEY_SECRET", "");
        String appKey = prefs.getString("APP_KEY", "");
        
        if (keyId.isEmpty() || keySecret.isEmpty() || appKey.isEmpty()) {
            throw new IllegalStateException("TTS credentials not configured");
        }
        
        return new CredentialConfig(keyId, keySecret, appKey);
    }
    
    // 在首次使用时设置配置
    public void setConfig(String dashScopeApiKey, String accessKeyId, 
                         String accessKeySecret, String appKey) {
        prefs.edit()
            .putString("DASHSCOPE_API_KEY", dashScopeApiKey)
            .putString("ACCESS_KEY_ID", accessKeyId)
            .putString("ACCESS_KEY_SECRET", accessKeySecret)
            .putString("APP_KEY", appKey)
            .apply();
    }
}
```

### 4. Android Service示例

#### ASR识别Service

```java
import com.example.tangyu.config.DashScopeConfig;
import com.example.tangyu.speech.*;

public class AsrService extends Service {
    private AsrClient asrClient;
    private AsrSessionManager sessionManager;
    private AsrSession currentSession;
    
    @Override
    public void onCreate() {
        super.onCreate();
        
        // 方式1：直接创建配置（推荐，简单直接）
        DashScopeConfig config = new DashScopeConfig(
            "sk-dcc82f29f97348deacf9969d27d209bf",  // 你的API Key
            null,  // 使用默认WebSocket地址
            null,  // 使用默认模型
            null   // 使用默认语言提示
        );
        
        // 方式2：使用配置工具类
        // DashScopeConfig config = SpeechConfigHelper.createDashScopeConfig();
        
        // 方式3：从SharedPreferences读取
        // ConfigManager configManager = new ConfigManager(this);
        // DashScopeConfig config = configManager.getDashScopeConfig();
        
        asrClient = new AsrClient(config);
        sessionManager = new AsrSessionManager(asrClient, "pcm", 16000);
    }
    
    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        String action = intent.getAction();
        
        if ("start_recognition".equals(action)) {
            startRecognition();
        } else if ("stop_recognition".equals(action)) {
            stopRecognition();
        } else if ("add_audio".equals(action)) {
            byte[] audioData = intent.getByteArrayExtra("audio_data");
            double rms = intent.getDoubleExtra("rms", 0.0);
            String mode = intent.getStringExtra("mode");
            if (audioData != null && currentSession != null) {
                currentSession.addAudio(audioData, rms, mode);
            }
        }
        
        return START_STICKY;
    }
    
    private void startRecognition() {
        String sessionId = "session-" + System.currentTimeMillis();
        currentSession = sessionManager.getOrCreateSession(sessionId);
        
        // 设置回调
        currentSession.onPartialResult(text -> {
            // 发送广播或使用EventBus通知Activity
            Intent intent = new Intent("ASR_PARTIAL_RESULT");
            intent.putExtra("text", text);
            sendBroadcast(intent);
        });
        
        currentSession.onFinalResult(text -> {
            Intent intent = new Intent("ASR_FINAL_RESULT");
            intent.putExtra("text", text);
            sendBroadcast(intent);
        });
        
        currentSession.onError(() -> {
            Intent intent = new Intent("ASR_ERROR");
            sendBroadcast(intent);
        });
        
        // 开始识别
        String mode = "normal"; // 或 "kws"
        currentSession.start(mode);
    }
    
    private void stopRecognition() {
        if (currentSession != null) {
            currentSession.end();
            sessionManager.removeSession(currentSession.getSessionId());
            currentSession = null;
        }
    }
    
    @Override
    public void onDestroy() {
        super.onDestroy();
        if (sessionManager != null) {
            sessionManager.clearAll();
        }
    }
    
    @Override
    public IBinder onBind(Intent intent) {
        return null;
    }
}
```

#### 在Activity中使用

```java
public class MainActivity extends AppCompatActivity {
    private BroadcastReceiver asrReceiver;
    private AsrService asrService;
    
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        
        // 初始化配置
        AndroidConfig.init(
            "your-api-key",
            "your-key-id",
            "your-secret",
            "your-app-key"
        );
        
        // 注册广播接收器
        asrReceiver = new BroadcastReceiver() {
            @Override
            public void onReceive(Context context, Intent intent) {
                String action = intent.getAction();
                if ("ASR_PARTIAL_RESULT".equals(action)) {
                    String text = intent.getStringExtra("text");
                    updatePartialResult(text);
                } else if ("ASR_FINAL_RESULT".equals(action)) {
                    String text = intent.getStringExtra("text");
                    updateFinalResult(text);
                } else if ("ASR_ERROR".equals(action)) {
                    handleError();
                }
            }
        };
        
        IntentFilter filter = new IntentFilter();
        filter.addAction("ASR_PARTIAL_RESULT");
        filter.addAction("ASR_FINAL_RESULT");
        filter.addAction("ASR_ERROR");
        registerReceiver(asrReceiver, filter);
        
        // 启动Service
        Intent serviceIntent = new Intent(this, AsrService.class);
        startService(serviceIntent);
    }
    
    private void startRecognition() {
        Intent intent = new Intent(this, AsrService.class);
        intent.setAction("start_recognition");
        startService(intent);
    }
    
    private void sendAudioData(byte[] audioData, double rms) {
        Intent intent = new Intent(this, AsrService.class);
        intent.setAction("add_audio");
        intent.putExtra("audio_data", audioData);
        intent.putExtra("rms", rms);
        intent.putExtra("mode", "normal");
        startService(intent);
    }
    
    private void stopRecognition() {
        Intent intent = new Intent(this, AsrService.class);
        intent.setAction("stop_recognition");
        startService(intent);
    }
    
    private void updatePartialResult(String text) {
        // 更新UI显示部分结果
        runOnUiThread(() -> {
            textViewPartial.setText(text);
        });
    }
    
    private void updateFinalResult(String text) {
        // 更新UI显示最终结果
        runOnUiThread(() -> {
            textViewFinal.setText(text);
        });
    }
    
    private void handleError() {
        runOnUiThread(() -> {
            Toast.makeText(this, "识别出错", Toast.LENGTH_SHORT).show();
        });
    }
    
    @Override
    protected void onDestroy() {
        super.onDestroy();
        if (asrReceiver != null) {
            unregisterReceiver(asrReceiver);
        }
        stopRecognition();
    }
}
```

### 5. 音频录制和发送

```java
public class AudioRecorder {
    private AudioRecord audioRecord;
    private boolean isRecording = false;
    private Thread recordingThread;
    private AsrService asrService;
    
    private static final int SAMPLE_RATE = 16000;
    private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;
    private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;
    private static final int BUFFER_SIZE = AudioRecord.getMinBufferSize(
        SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT
    );
    
    public void startRecording(AsrService service) {
        this.asrService = service;
        
        audioRecord = new AudioRecord(
            MediaRecorder.AudioSource.MIC,
            SAMPLE_RATE,
            CHANNEL_CONFIG,
            AUDIO_FORMAT,
            BUFFER_SIZE
        );
        
        audioRecord.startRecording();
        isRecording = true;
        
        recordingThread = new Thread(() -> {
            byte[] buffer = new byte[BUFFER_SIZE];
            while (isRecording) {
                int read = audioRecord.read(buffer, 0, BUFFER_SIZE);
                if (read > 0) {
                    // 计算RMS
                    double rms = calculateRMS(buffer, read);
                    
                    // 发送到ASR Service
                    Intent intent = new Intent(service, AsrService.class);
                    intent.setAction("add_audio");
                    intent.putExtra("audio_data", Arrays.copyOf(buffer, read));
                    intent.putExtra("rms", rms);
                    intent.putExtra("mode", "normal");
                    service.startService(intent);
                }
            }
        });
        
        recordingThread.start();
    }
    
    public void stopRecording() {
        isRecording = false;
        if (audioRecord != null) {
            audioRecord.stop();
            audioRecord.release();
            audioRecord = null;
        }
    }
    
    private double calculateRMS(byte[] buffer, int length) {
        long sum = 0;
        for (int i = 0; i < length; i += 2) {
            short sample = (short) ((buffer[i] & 0xFF) | (buffer[i + 1] << 8));
            sum += sample * sample;
        }
        return Math.sqrt(sum / (length / 2.0));
    }
}
```

### 6. Android注意事项

1. **网络请求**：确保在主线程外执行网络操作
2. **权限处理**：Android 6.0+需要运行时权限申请
3. **生命周期管理**：在Activity/Fragment销毁时清理资源
4. **线程安全**：使用Handler或LiveData更新UI
5. **ProGuard配置**：如果使用代码混淆，需要添加规则

```proguard
-keep class com.example.tangyu.** { *; }
-keep class com.alibaba.dashscope.** { *; }
-keep class com.aliyun.** { *; }
-dontwarn com.example.tangyu.**
```

---

## ASR功能详解

### 1. 文本去重处理 (`TextDeduplicator`)

参照Python的`deduplicate_text`函数实现：

- 去除连续重复的字符（如 "你你你" -> "你"）
- 去除连续重复的短语（2-6字）
- 清理多余空格
- 修复多个连续标点符号

**使用示例：**
```java
String text = "你好你好，你是谁你是谁？";
String cleaned = TextDeduplicator.deduplicate(text);
// 结果: "你好，你是谁？"
```

### 2. ASR会话管理 (`AsrSession`)

参照Python的`handle_client`函数实现，支持：

- **音频缓冲管理**：累积音频数据，支持分块处理
- **KWS模式**：关键词唤醒模式，更快的识别响应（每8个块识别一次，约0.4秒）
- **正常ASR模式**：实时发送音频数据，每10个块发送进度
- **模式切换**：支持在KWS和正常模式间切换
- **音频长度检查**：过滤太短的音频（< 0.3秒）

**主要方法：**
- `start(String mode)` - 开始识别（"kws" 或 "normal"）
- `addAudio(byte[] audioData, double rms, String mode)` - 添加音频数据
- `end()` - 结束当前句子识别
- `abort()` - 打断当前识别
- `stop()` - 停止会话

**使用示例：**
```java
AsrSession session = new AsrSession("session-1", asrClient, "pcm", 16000);

// 设置回调
session.onPartialResult(text -> System.out.println("部分: " + text));
session.onFinalResult(text -> System.out.println("最终: " + text));
session.onProgress(progress -> System.out.println("进度: " + progress));

// 开始识别
session.start("normal");

// 发送音频数据
byte[] audioData = getAudioData();
session.addAudio(audioData, 0.5, "normal");

// 结束识别
session.end();
```

### 3. 增强的结果处理器 (`AsrResultHandler`)

- 支持部分结果（partial）和最终结果（final）的区分
- 集成文本去重功能
- 支持自定义回调函数

**使用示例：**
```java
AsrResultHandler handler = new AsrResultHandler(true); // 启用去重

handler.setOnPartialResult(text -> {
    System.out.println("部分结果: " + text);
});

handler.setOnFinalResult(text -> {
    System.out.println("最终结果: " + text);
});

Recognition recognition = asrClient.startStreaming("pcm", 16000, handler);
```

### 4. 会话管理器 (`AsrSessionManager`)

参照Python的多客户端管理逻辑：

- 管理多个识别会话
- 支持会话的创建、获取、移除
- 清理所有会话

**使用示例：**
```java
AsrSessionManager manager = new AsrSessionManager(asrClient, "pcm", 16000);

// 创建会话
AsrSession session = manager.getOrCreateSession("session-1");

// 使用会话...

// 移除会话
manager.removeSession("session-1");

// 清理所有会话
manager.clearAll();
```

### 完整使用示例

```java
import com.example.tangyu.config.DashScopeConfig;
import com.example.tangyu.speech.*;

// 1. 初始化
DashScopeConfig config = DashScopeConfig.fromEnvironment();
AsrClient asrClient = new AsrClient(config);
AsrSessionManager manager = new AsrSessionManager(asrClient, "pcm", 16000);

// 2. 创建会话
AsrSession session = manager.getOrCreateSession("session-1");

// 3. 设置回调
session.onPartialResult(text -> {
    if (!text.isEmpty()) {
        System.out.println("部分结果: " + text);
    }
});

session.onFinalResult(text -> {
    if (!text.isEmpty()) {
        System.out.println("最终结果: " + text);
    }
});

// 4. 开始识别
session.start("normal"); // 或 "kws"

// 5. 发送音频数据（模拟）
byte[] audioChunk = new byte[3200]; // 100ms音频
for (int i = 0; i < 20; i++) {
    session.addAudio(audioChunk, 0.5, "normal");
    Thread.sleep(100);
}

// 6. 结束识别
session.end();

// 7. 清理
manager.removeSession("session-1");
```

---

## 配置说明

### 环境变量

| 变量名 | 说明 | 是否必需 | 默认值 |
|--------|------|---------|--------|
| `DASHSCOPE_API_KEY` | DashScope API密钥 | 是 | - |
| `DASHSCOPE_BASE_URL` | WebSocket API地址 | 否 | `wss://dashscope.aliyuncs.com/api-ws/v1/inference` |
| `DASHSCOPE_ASR_MODEL` | ASR模型名称 | 否 | `fun-asr-realtime` |
| `DASHSCOPE_ASR_LANGUAGE_HINTS` | 语言提示（逗号分隔） | 否 | `zh,en` |
| `ALIBABA_CLOUD_ACCESS_KEY_ID` | 阿里云AccessKey ID | 是（TTS） | - |
| `ALIBABA_CLOUD_ACCESS_KEY_SECRET` | 阿里云AccessKey Secret | 是（TTS） | - |
| `ALIBABA_CLOUD_APP_KEY` | 语音服务AppKey | 是（TTS） | - |

### 系统属性

也可以通过JVM系统属性设置：

```bash
java -Ddashscope.apiKey=your-key -Ddashscope.baseUrl=wss://... YourApp
```

---

## 常见问题

### Q: 如何查看依赖树？
```bash
mvn dependency:tree
```

### Q: 如何跳过测试打包？
```bash
mvn clean package -DskipTests
```

### Q: 依赖冲突怎么办？
如果项目中已有相同依赖的不同版本，可能需要排除或统一版本。使用 `mvn dependency:tree` 查看依赖树。

### Q: Android中如何配置？
参考 [Android服务调用](#android服务调用) 章节，使用SharedPreferences或配置类设置API密钥。

### Q: 可以用于生产环境吗？
可以，但建议：
1. 添加重试机制
2. 添加连接池管理
3. 添加监控和日志
4. 处理异常情况
5. 实现资源清理和生命周期管理

### Q: 如何发布到私有Maven仓库？
```bash
mvn deploy -DaltDeploymentRepository=your-repo::default::http://your-repo-url
```

### Q: KWS模式和正常模式有什么区别？
- **KWS模式**：每8个块识别一次（约0.4秒），适用于需要快速响应的场景
- **正常模式**：实时发送音频数据，适用于完整句子识别

### Q: 音频格式要求？
- 格式：PCM
- 采样率：16kHz
- 位深：16bit
- 声道：单声道

---

## 主要模块说明

- `DashScopeConfig`：读取 Fun-ASR 相关配置（API Key、可选的 baseUrl/model/language_hints）
- `CredentialConfig`：从环境/系统属性读取并校验 AccessKey 与 AppKey（仅 TTS 使用）
- `TokenClient`：使用阿里云 SDK 获取并缓存临时 Token（默认 30 分钟，预留 60 秒更新缓冲）
- `AsrClient`：基于 DashScope Fun-ASR Java SDK 的同步调用和流式调用
- `AsrSession`：ASR会话管理，支持KWS模式和正常模式
- `AsrSessionManager`：多会话管理器
- `AsrResultHandler`：识别结果处理器，支持部分结果和最终结果
- `TextDeduplicator`：文本去重处理器
- `TtsClient`：通过阿里云NLS接口生成音频并保存到文件
- `DemoMain`：简单 CLI，分别支持 `asr`、`asr-stream` 与 `tts` 子命令

---

## 注意事项

1. **JDK版本**：需要JDK 17或更高版本
2. **依赖冲突**：如果项目中已有相同依赖的不同版本，可能需要解决版本冲突
3. **环境变量**：确保正确配置了所需的环境变量或系统属性
4. **网络连接**：需要能够访问阿里云服务
5. **日志配置**：项目使用SLF4J，可以根据需要配置具体的日志实现（如Logback、Log4j2等）
6. **Android权限**：需要网络权限和录音权限（如果使用麦克风）
7. **线程安全**：在Android中使用时，注意在主线程外执行网络操作，使用Handler更新UI

---

## 参考文件

- Python实现：`src/main/java/com/example/tangyu/speech/funasr_ws_server.py`
- Java实现：
  - `TextDeduplicator.java` - 文本去重
  - `AsrSession.java` - 会话管理
  - `AsrSessionManager.java` - 会话管理器
  - `AsrResultHandler.java` - 结果处理器（增强版）
  - `AsrClient.java` - ASR客户端
  - `TtsClient.java` - TTS客户端

